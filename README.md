There are four files attched in this repo along with the Jupyter Noitebook used for scraping on the given data using selenium. Each file consists all the urls of the particular category. 
# There are a few columns empty or Invalid in "TEXT" parameter because few of the websites loaded on the ReCapcha Page / Cookies Permission page which caused to program to extract that text or skip to the next website.

This was my first time using selenium but I tried my best to satisfy the requirements of the assignment.
